{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Imports and Setup"
      ],
      "metadata": {
        "id": "YoLxFDbmhVbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTBkNQgib3xj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "num_folds = 5\n",
        "epochs = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Download and Unzip Dataset"
      ],
      "metadata": {
        "id": "Ca2gisMAhcHa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdxAYqwZbRTb",
        "outputId": "1d89ea5a-bcb4-4335-c377-a5a0fe050389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cats_and_dogs_filtered.zip\n",
            "replace cats_and_dogs_filtered/vectorize.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
        "!unzip cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: Dataset Creation Function"
      ],
      "metadata": {
        "id": "L1VtuQfUjw9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzVjGFNzbcaV"
      },
      "outputs": [],
      "source": [
        "def create_datasets(path):\n",
        "    image_paths=[]\n",
        "    image_labels=[]\n",
        "\n",
        "    for dir in os.listdir(path):\n",
        "        for file in os.listdir(f'{path}/{dir}'):\n",
        "            image_path=f'{path}/{dir}/{file}'\n",
        "            image_label=0 if dir ==\"cats\" else 1\n",
        "\n",
        "            image_paths.append(image_path)\n",
        "            image_labels.append(image_label)\n",
        "\n",
        "\n",
        "    image_paths=np.array(image_paths)\n",
        "    image_labels=np.array(image_labels)\n",
        "\n",
        "    return image_paths,image_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: Load Training and Testing Data"
      ],
      "metadata": {
        "id": "Mqby4VeSj8Ya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg9ehqIvbcc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb5e67f-edd3-4825-d0c3-023f5cd36851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000,) (2000,) (1000,) (1000,)\n",
            "/content/cats_and_dogs_filtered/train/cats/cat.114.jpg 0\n"
          ]
        }
      ],
      "source": [
        "image_train,label_train=create_datasets('/content/cats_and_dogs_filtered/train')\n",
        "image_test,label_test=create_datasets('/content/cats_and_dogs_filtered/validation')\n",
        "print(image_train.shape,label_train.shape,image_test.shape,label_test.shape)\n",
        "print(image_train[0], label_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5: Image Preprocessing Functions"
      ],
      "metadata": {
        "id": "xR6k9Dg3hoWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XisMR5Xdbcnc"
      },
      "outputs": [],
      "source": [
        "def get_image_tensor_from_path(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (244, 244))\n",
        "    return image, label\n",
        "\n",
        "def augment_image(image, label):\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
        "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6: Create TensorFlow Dataset Function"
      ],
      "metadata": {
        "id": "RHgnGMWbkOI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZLxb46cbcsc"
      },
      "outputs": [],
      "source": [
        "def cd_dataset(x, y, batch_size=32, training=False):\n",
        "    data = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    data = data.map(get_image_tensor_from_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    if training:\n",
        "        data = data.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    data = data.shuffle(2000)\n",
        "    data = data.batch(batch_size)\n",
        "    data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return data\n",
        "\n",
        "train_dataset=cd_dataset(image_train,label_train,training=True)\n",
        "test_dataset=cd_dataset(image_test,label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7: Data Visualization"
      ],
      "metadata": {
        "id": "NsLui6Wmkafv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "484dj2Sebl0X",
        "outputId": "f4229973-20be-4c87-8ce8-61e51d76b8bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b9d8d607c856>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3082\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \"output_shapes\", output_shapes)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class_names = ['cat', 'dog']\n",
        "\n",
        "for x, y in test_dataset.take(1):\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "\n",
        "  for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(x[i])\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.xlabel(class_names[y[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8: Model Definition and Compilation"
      ],
      "metadata": {
        "id": "SbilVSh8kgGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b_model = VGG16(input_shape=(244, 244, 3),include_top=False,weights='imagenet')\n",
        "b_model.trainable = False\n",
        "b_model.summary()"
      ],
      "metadata": {
        "id": "yGiNf-mG5Bw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwEjEJlDbl3C"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    b_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=256,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "   ]\n",
        ")\n",
        "model.compile('adam',loss='binary_crossentropy',metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9: Training with Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "kPy4bAYokxI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnR1BhF0bsKo"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=3,min_lr=1e-6)\n",
        "history = model.fit(train_dataset,epochs=8,validation_data=test_dataset,callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10: Plot Training History"
      ],
      "metadata": {
        "id": "mSoAd1Kzk6kR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0DsSnVBbsFH"
      },
      "outputs": [],
      "source": [
        "train_history = pd.DataFrame(model.history.history)\n",
        "train_history[['loss','val_loss']].plot(title=\"Loss Over Epochs\")\n",
        "train_history[['acc', 'val_acc']].plot(title=\"Accuracy Over Epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11: Model Evaluation on Test Set"
      ],
      "metadata": {
        "id": "KW8Ljno9lCHR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmPni5E6bsP1"
      },
      "outputs": [],
      "source": [
        "test_loss,test_accuracy = model.evaluate(test_dataset)\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12: Prediction Function with Visualization"
      ],
      "metadata": {
        "id": "dbSQDeVYlGGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvoX9siUbsSQ"
      },
      "outputs": [],
      "source": [
        "def predict_and_show(start_index=None, num_samples=5,external_path=None):\n",
        "    if external_path:\n",
        "        image_paths = [external_path]\n",
        "        actual_labels = [None]\n",
        "    else:\n",
        "        image_paths = image_test[start_index:start_index + num_samples]\n",
        "        actual_labels = [\"Dog\" if label == 1 else \"Cat\" for label in label_test[start_index:start_index + num_samples]]\n",
        "\n",
        "    num_samples = len(image_paths)\n",
        "    num_rows = (num_samples + 4) // 5\n",
        "    fig, axes = plt.subplots(num_rows, 5, figsize=(15, 3 * num_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        image_path = image_paths[i]\n",
        "        actual_label = actual_labels[i]\n",
        "\n",
        "        image, _ = get_image_tensor_from_path(image_path, label=None)\n",
        "        image_expanded = np.expand_dims(image, axis=0)\n",
        "\n",
        "        prediction = model.predict(image_expanded)\n",
        "        predicted_label = \"Dog\" if prediction[0] > 0.5 else \"Cat\"\n",
        "\n",
        "        axes[i].imshow(image)\n",
        "        title = f\"Predicted: {predicted_label}\"\n",
        "        if actual_label is not None:\n",
        "            title += f\"\\nActual: {actual_label}\"\n",
        "        title += f\"\\nConfidence: {prediction[0][0]:.2f}\"\n",
        "        axes[i].set_title(title, fontsize=10, pad=10)\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    for j in range(num_samples, len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_show(start_index=100,num_samples=11)\n"
      ],
      "metadata": {
        "id": "8BErkpJghurP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_show(external_path='/content/image1.jpeg')"
      ],
      "metadata": {
        "id": "O5lOVFYvgvFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_show(external_path='/content/image2.jpg')"
      ],
      "metadata": {
        "id": "6_STo5vFqBbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13: K-Fold Cross-Validation"
      ],
      "metadata": {
        "id": "5U4j1bg1lTS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "fold_nb = 1\n",
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train_index, test_index in kf.split(image_train):\n",
        "    train_images, test_images = image_train[train_index], image_train[test_index]\n",
        "    train_labels, test_labels = label_train[train_index], label_train[test_index]\n",
        "\n",
        "    train_dataset = cd_dataset(train_images, train_labels, batch_size=32, training=True)\n",
        "    test_dataset = cd_dataset(test_images, test_labels, batch_size=32)\n",
        "\n",
        "    b_model = VGG16(input_shape=(244, 244, 3), include_top=False, weights='imagenet')\n",
        "    b_model.trainable = False\n",
        "\n",
        "    model=tf.keras.Sequential([\n",
        "    b_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=256,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "   ])\n",
        "\n",
        "    model.compile('adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "    print(f'Fold{fold_nb}.....')\n",
        "    model.fit(train_dataset,epochs=epochs,validation_data=test_dataset,callbacks=[lr_scheduler])\n",
        "\n",
        "    scores = model.evaluate(test_dataset)\n",
        "    accuracy_per_fold.append(scores[1])\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    fold_nb += 1\n",
        "\n",
        "print(f\"Average accuracy across folds: {np.mean(accuracy_per_fold):.4f}\")\n",
        "print(f\"Average loss across folds: {np.mean(loss_per_fold):.4f}\")\n"
      ],
      "metadata": {
        "id": "yijJX97wn9Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14: Model Save"
      ],
      "metadata": {
        "id": "syu8m1pdlWxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"cats_dogs_classifier.h5\")\n"
      ],
      "metadata": {
        "id": "UxBZGuYcn9a7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}